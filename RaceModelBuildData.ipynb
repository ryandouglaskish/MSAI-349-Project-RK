{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "\n",
    "linestyles = OrderedDict(\n",
    "    [\n",
    "\n",
    "     ('loosely dashed',      (0, (5, 20))),\n",
    "     ('dashed',              (0, (3, 2))),\n",
    "     ('densely dashed',      (0, (1, 3))),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circuits_raw_df Index(['circuitId', 'circuitRef', 'name', 'location', 'country', 'lat', 'lng',\n",
      "       'alt', 'url'],\n",
      "      dtype='object')\n",
      "constructors_raw_df Index(['constructorId', 'constructorRef', 'name', 'nationality', 'url'], dtype='object')\n",
      "constructor_standings_raw_df Index(['constructorStandingsId', 'raceId', 'constructorId', 'points',\n",
      "       'position', 'positionText', 'wins'],\n",
      "      dtype='object')\n",
      "driver_standings_raw_df Index(['driverStandingsId', 'raceId', 'driverId', 'points', 'position',\n",
      "       'positionText', 'wins'],\n",
      "      dtype='object')\n",
      "drivers_raw_df Index(['driverId', 'driverRef', 'number', 'code', 'forename', 'surname', 'dob',\n",
      "       'nationality', 'url'],\n",
      "      dtype='object')\n",
      "laptimes_raw_df Index(['raceId', 'driverId', 'lap', 'position', 'time', 'milliseconds'], dtype='object')\n",
      "pitstops_raw_df Index(['raceId', 'driverId', 'stop', 'lap', 'time', 'duration',\n",
      "       'milliseconds'],\n",
      "      dtype='object')\n",
      "qualifying_raw_df Index(['qualifyId', 'raceId', 'driverId', 'constructorId', 'number',\n",
      "       'position', 'q1', 'q2', 'q3'],\n",
      "      dtype='object')\n",
      "races_raw_df Index(['raceId', 'year', 'round', 'circuitId', 'name', 'date', 'time', 'url',\n",
      "       'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time',\n",
      "       'quali_date', 'quali_time', 'sprint_date', 'sprint_time'],\n",
      "      dtype='object')\n",
      "results_raw_df Index(['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid',\n",
      "       'position', 'positionText', 'positionOrder', 'points', 'laps', 'time',\n",
      "       'milliseconds', 'fastestLap', 'rank', 'fastestLapTime',\n",
      "       'fastestLapSpeed', 'statusId'],\n",
      "      dtype='object')\n",
      "seasons_raw_df Index(['year', 'url'], dtype='object')\n",
      "sprint_results Index(['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid',\n",
      "       'position', 'positionText', 'positionOrder', 'points', 'laps', 'time',\n",
      "       'milliseconds', 'fastestLap', 'fastestLapTime', 'statusId'],\n",
      "      dtype='object')\n",
      "status_raw_df Index(['statusId', 'status'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def load_kaggle_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data.replace({'\\\\N':np.nan}, inplace=True)\n",
    "    return data\n",
    "\n",
    "data_dir ='kaggle-data/'\n",
    "\n",
    "circuits_raw_df = load_kaggle_data(f'{data_dir}/circuits.csv')\n",
    "constructors_raw_df = load_kaggle_data(f'{data_dir}/constructors.csv')\n",
    "constructor_standings_raw_df = load_kaggle_data(f'{data_dir}/constructor_standings.csv')\n",
    "driver_standings_raw_df = load_kaggle_data(f'{data_dir}/driver_standings.csv')\n",
    "drivers_raw_df = load_kaggle_data(f'{data_dir}/drivers.csv')\n",
    "laptimes_raw_df = load_kaggle_data(f'{data_dir}/lap_times.csv')\n",
    "pitstops_raw_df = load_kaggle_data(f'{data_dir}/pit_stops.csv')\n",
    "qualifying_raw_df = load_kaggle_data(f'{data_dir}/qualifying.csv')\n",
    "races_raw_df = load_kaggle_data(f'{data_dir}/races.csv')\n",
    "results_raw_df = load_kaggle_data(f'{data_dir}/results.csv')\n",
    "seasons_raw_df = load_kaggle_data(f'{data_dir}/seasons.csv')\n",
    "sprint_results = load_kaggle_data(f'{data_dir}/sprint_results.csv')\n",
    "status_raw_df = load_kaggle_data(f'{data_dir}/status.csv')\n",
    "\n",
    "print('circuits_raw_df', circuits_raw_df.columns)\n",
    "print('constructors_raw_df', constructors_raw_df.columns)\n",
    "print('constructor_standings_raw_df', constructor_standings_raw_df.columns)\n",
    "print('driver_standings_raw_df', driver_standings_raw_df.columns)\n",
    "print('drivers_raw_df', drivers_raw_df.columns)\n",
    "print('laptimes_raw_df', laptimes_raw_df.columns)\n",
    "print('pitstops_raw_df', pitstops_raw_df.columns)\n",
    "print('qualifying_raw_df', qualifying_raw_df.columns)\n",
    "print('races_raw_df', races_raw_df.columns)\n",
    "print('results_raw_df', results_raw_df.columns)\n",
    "print('seasons_raw_df', seasons_raw_df.columns)\n",
    "print('sprint_results', sprint_results.columns)\n",
    "print('status_raw_df', status_raw_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data\n",
    "Note: not filtering for drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process drivers data set\n",
    "\n",
    "# drivers = drivers_raw_df[['driverId','forename','surname','number']].reset_index(drop=True)\n",
    "# # Make name column\n",
    "# drivers['Name'] = drivers[['forename', 'surname']].agg(' '.join, axis=1)\n",
    "# drivers.drop(['forename','surname'], axis=1, inplace=True)\n",
    "\n",
    "# driver_name_id_map = dict(zip(drivers['Name'], drivers['driverId']))\n",
    "# def get_driverID(name):\n",
    "#     return drivers.loc[drivers['Name']==name, 'driverId'].squeeze()\n",
    "\n",
    "# driver_name_number_map = dict(zip(drivers['Name'], drivers['number']))\n",
    "# def get_driver_number(name):\n",
    "#     return drivers.loc[drivers['Name']==name, 'number'].squeeze()\n",
    "\n",
    "# driver_names_of_interest = ['Max Verstappen',\n",
    "#                            'Sergio Pérez',\n",
    "#                            'Lewis Hamilton',\n",
    "#                            'Fernando Alonso',\n",
    "#                            'Charles Leclerc',\n",
    "#                            'Lando Norris',\n",
    "#                            'George Russell',\n",
    "#                            'Oscar Piastri',\n",
    "#                            'Lance Stroll',\n",
    "#                            'Pierre Gasly',\n",
    "#                            'Esteban Ocon',\n",
    "#                            'Alexander Albon',\n",
    "#                            'Nico Hülkenberg',\n",
    "#                            'Valtteri Bottas',\n",
    "#                            'Guanyu Zhou',\n",
    "#                            'Yuki Tsunoda',\n",
    "#                            'Kevin Magnussen',\n",
    "#                            #'Liam Lawson',\n",
    "#                            'Logan Sargeant',\n",
    "#                            'Nyck de Vries',\n",
    "#                            'Daniel Ricciardo']\n",
    "# driver_ids_of_interest = [driver_name_id_map[name] for name in driver_names_of_interest]\n",
    "\n",
    "# driver_numbers_of_interest = [driver_name_number_map[name] for name in driver_names_of_interest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First year: 1965\n",
      "# Races: 960\n"
     ]
    }
   ],
   "source": [
    "# Driver name\n",
    "drivers = drivers_raw_df[['driverId','forename','surname','number']].reset_index(drop=True)\n",
    "drivers['Name'] = drivers[['forename', 'surname']].agg(' '.join, axis=1)\n",
    "drivers.drop(['forename','surname'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# start with race results\n",
    "# extend positionText labels (see EDA)\n",
    "results_raw_df['positionText'] = results_raw_df['positionText'].replace({'R':'Retired','D':'Disqualified','N':'not classified', 'E':'Excluded','W':'Withdrawn','F':'failed to qualify'})\n",
    "# drop time, milliseconds, fastestLap, rank, fastestLapTime, fastestLapSpeed, and number (http://ergast.com/mrd/methods/results/)\n",
    "races = results_raw_df.drop(['time','milliseconds','fastestLap','rank','fastestLapTime','fastestLapSpeed','number'], axis=1)\n",
    "races.drop(['positionOrder'], axis=1, inplace=True)\n",
    "races['position'].fillna('NaN', inplace=True)\n",
    "#display(races.isna().sum())\n",
    "assert races.isna().sum().sum() == 0, 'there are null values'\n",
    "\n",
    "# Get race data (ignoring qualifying data)\n",
    "races_raw_df.rename(columns={'name':'Race'}, inplace=True)\n",
    "prev_len = races.shape[0]\n",
    "races = races.merge(races_raw_df[['raceId','Race','round','circuitId','date','url']], on='raceId', how='left')\n",
    "assert races.shape[0] == prev_len, 'confirm no duplicates formed during merge'\n",
    "assert races.isna().sum().sum() == 0\n",
    "\n",
    "# Explode date\n",
    "races['date'] = pd.to_datetime(races['date'])\n",
    "races['Month'] = races['date'].dt.month\n",
    "races['Year'] = races['date'].dt.year\n",
    "#races.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "# Filter year due to bad quality data in early years (multiple results reported for a driver in a race) -- see EDA for details\n",
    "races = races[races['Year']>1964].reset_index(drop=True)\n",
    "assert races.groupby(['raceId','driverId'])['position'].nunique().max()==1, 'there are multiple positions reported for a driver in a race'\n",
    "\n",
    "# Merge with drivers\n",
    "prev_len = races.shape[0]\n",
    "races = races.merge(drivers[['driverId','Name']], on='driverId', how='left')\n",
    "assert races.shape[0] == prev_len, 'confirm no duplicates formed during merge'\n",
    "assert races['Name'].isna().sum() == 0\n",
    "\n",
    "\n",
    "# # Filter for drivers of interest\n",
    "# races = races[races['Name'].isin(driver_names_of_interest)].reset_index(drop=True)\n",
    "# assert races['driverId'].nunique() == len(driver_ids_of_interest), 'confirm we have lap data for all drivers of interest'\n",
    "# #races.drop(['driverId'], axis=1, inplace=True)\n",
    "# assert races.groupby(['raceId','Name']).size().max() == 1, 'driver occurs twice in a race'\n",
    "# assert races.groupby(['raceId','driverId'])['position'].nunique().max() == 1\n",
    "\n",
    "\n",
    "# Get status string\n",
    "prev_len = races.shape[0]\n",
    "races = races.merge(status_raw_df[['statusId','status']], on='statusId', how='left')\n",
    "assert races['status'].isna().sum() == 0\n",
    "assert races.shape[0] == prev_len, 'confirm no duplicates formed during merge'\n",
    "races.drop(['statusId'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Get car name\n",
    "prev_len = races.shape[0]\n",
    "constructors_raw_df.rename(columns={'name':'Car'}, inplace=True)\n",
    "car_names = constructors_raw_df['Car'].unique()\n",
    "races = races.merge(constructors_raw_df[['constructorId','Car']], on='constructorId', how='left')\n",
    "assert races.shape[0] == prev_len, 'confirm no duplicates formed during merge'\n",
    "assert races['Car'].isna().sum() == 0\n",
    "races.drop(['constructorId'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Get circuit data\n",
    "prev_len = races.shape[0]\n",
    "circuits_raw_df.rename(columns={'name':'Circuit'}, inplace=True)\n",
    "circuits_raw_df['alt'].fillna(circuits_raw_df['alt'].median(), inplace=True) # impute median altitude -- #todo may want to change\n",
    "races = races.merge(circuits_raw_df[['circuitId','Circuit','location','country','alt','lat','lng']], on='circuitId', how='left')\n",
    "assert races.shape[0] == prev_len, 'confirm no duplicates formed during merge'\n",
    "assert races.isna().sum().sum() == 0\n",
    "races.drop(['circuitId'], axis=1, inplace=True)\n",
    "\n",
    "# Get number of laps in the race\n",
    "number_of_laps = results_raw_df[results_raw_df['statusId']==1].groupby(['raceId'])['laps'].max().reset_index(name='nlaps')\n",
    "assert races.isna().sum().sum() == 0, 'there is at least one race where none of the drivers finished -- cannot find number of laps in the race'\n",
    "prev_len = races.shape[0]\n",
    "races = races.merge(number_of_laps, on='raceId',how='left')\n",
    "assert races.shape[0] == prev_len, 'confirm no duplicates formed during merge'\n",
    "assert races.isna().sum().sum() == 0, 'there is at least one race where none of the drivers finished -- cannot find number of laps in the race'\n",
    "races.drop(['laps'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Summary\n",
    "print('First year:',  races['Year'].min())\n",
    "print('# Races:', races['raceId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Race Model Filters\n",
    "\n",
    "# # filter for races with 32 or fewer drivers\n",
    "# prev_n_races = races['raceId'].nunique()\n",
    "\n",
    "# valid_races = races.groupby('raceId').size()\n",
    "# valid_races = valid_races[valid_races<=32].index\n",
    "# races = races[races['raceId'].isin(valid_races)].reset_index(drop=True)\n",
    "# print('Races removed:', prev_n_races - races['raceId'].nunique(), '({} races now)'.format(races['raceId'].nunique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Races removed: 0\n"
     ]
    }
   ],
   "source": [
    "## Dynamic race model filters\n",
    "\n",
    "# when number of race laps < k + threshold\n",
    "k = 10\n",
    "threshold = k*2\n",
    "prev_n_races = races['raceId'].nunique()\n",
    "race_counts = races['raceId'].value_counts()\n",
    "valid_races = race_counts[race_counts > 10].index\n",
    "races = races[races['raceId'].isin(valid_races)].reset_index(drop=True)\n",
    "print('Races removed:', prev_n_races - races['raceId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique races 960\n"
     ]
    }
   ],
   "source": [
    "print('unique races', races['raceId'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model Data With Lap Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds padding rows to races with less than 24 drivers\n",
    "def pad_race(group, target_rows=24, invalid_finishing_position_num=25):\n",
    "    current_rows = group.shape[0]\n",
    "    # If the current number of rows is less than the target, pad the group\n",
    "    if current_rows < target_rows:\n",
    "        # Calculate the number of rows to append\n",
    "        rows_to_add = target_rows - current_rows\n",
    "        # Create a DataFrame with the same columns, filled with NaNs\n",
    "        padding_df = pd.DataFrame(np.nan, index=range(rows_to_add), columns=group.columns)\n",
    "        # Assign the raceId to the padding DataFrame\n",
    "        padding_df['raceId'] = group['raceId'].iloc[0]\n",
    "        padding_df['driverId'] = -1\n",
    "        padding_df['y'] = invalid_finishing_position_num\n",
    "        if 'coef' in padding_df.columns:\n",
    "            padding_df['coef'] = group['coef'].max() + group['coef'].std()\n",
    "            #print('padding_df', padding_df['coef'].max())\n",
    "\n",
    "        # Append the padding DataFrame to the group\n",
    "        group = pd.concat([group, padding_df], ignore_index=True)\n",
    "    return group\n",
    "\n",
    "# Replace race driver order with random order with num_copies copies\n",
    "def randomize_race(group, num_copies=4):\n",
    "    randomized_races = []\n",
    "    race_id = group['raceId'].iloc[0]\n",
    "\n",
    "    # Create each random copy\n",
    "    for i in range(num_copies):\n",
    "        randomized_group = group.sample(frac=1, replace=False, random_state=i+1).reset_index(drop=True)\n",
    "        randomized_group['copy_id'] = f\"{race_id}_{i}\"  # Create a unique ID for each copy\n",
    "        randomized_races.append(randomized_group)\n",
    "    \n",
    "    # Concatenate\n",
    "    return pd.concat(randomized_races, ignore_index=True)\n",
    "\n",
    "def train_test_split_by_id(df, id_column, train_size=0.8):\n",
    "    unique_ids = df[id_column].unique()\n",
    "    \n",
    "    train_ids, temp_ids = train_test_split(unique_ids, train_size=train_size, random_state=100)\n",
    "\n",
    "    test_ids, valid_ids = train_test_split(temp_ids, train_size=0.5, random_state=100)\n",
    "\n",
    "    train_df = df[df[id_column].isin(train_ids)]\n",
    "    valid_df = df[df[id_column].isin(valid_ids)]\n",
    "    test_df = df[df[id_column].isin(test_ids)]\n",
    "    \n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "def pivot_model_data(df):\n",
    "\n",
    "    # value columns\n",
    "    laps_and_y_cols = [col for col in df.columns if 'lap_' in col or col == 'y' or col == 'coef']\n",
    "\n",
    "    pivot = df.pivot_table(index='copy_id', \n",
    "                        columns=['model_driverId'], \n",
    "                        values=laps_and_y_cols, fill_value=np.nan)\n",
    "\n",
    "    # Flatten the MultiIndex in columns\n",
    "    #pivot.columns = [f'model_driver{model_driver_id}_{lap_id}pos' if lap_id else 'copy_id' for model_driver_id, lap_id in pivot.columns]\n",
    "    new_columns = []\n",
    "    for col in pivot.columns.tolist()[:]:\n",
    "        # Concatenate the model_driverId with the lap information\n",
    "        driver_number = 'driver' + str(col[1])  # Increment model_driverId by 1 to start numbering from 1\n",
    "        lap_info = col[0]\n",
    "        new_columns.append(f'{driver_number}_{lap_info}')\n",
    "    pivot.columns = new_columns\n",
    "    pivot.reset_index(inplace=True, drop=False)\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_data(laptimes_raw_df, races, laps_to_consider, laps_text, path, coef=False, race_copies=3, metric='milliseconds'):\n",
    "    # get laptimes (note: all races in laptimes_raw_df are in races dataframe)\n",
    "    laptimes = laptimes_raw_df[laptimes_raw_df['raceId'].isin(races['raceId'].unique())].reset_index(drop=True)[['raceId','driverId','lap','position','milliseconds']]\n",
    "    n_drivers = laptimes.groupby(['raceId'])['driverId'].nunique().max()\n",
    "    print('max number drivers per race', n_drivers)\n",
    "\n",
    "    # calculate driver finishing times\n",
    "    driver_finishing_times = laptimes.groupby(['raceId','driverId'])['milliseconds'].sum().reset_index(name='finishing_time') # todo: fix where driver doesn't finish\n",
    "\n",
    "    # filter data so that it corresponds to desired feature set\n",
    "    laptimes = laptimes[laptimes['lap'].isin(laps_to_consider)].reset_index(drop=True)\n",
    "\n",
    "    laptimes['lap'] = 'lap_' + laptimes['lap'].astype(str).str.zfill(2)\n",
    "    #print(laptimes['lap'].unique())\n",
    "\n",
    "    # pivot lap data\n",
    "    if metric == 'milliseconds':\n",
    "        model_data = laptimes.pivot_table(index=['raceId','driverId'], columns=['lap'], values=metric, fill_value=0)  # fill missing values with 0\n",
    "    elif metric == 'position':\n",
    "        model_data = laptimes.pivot_table(index=['raceId','driverId'], columns=['lap'], values=metric, fill_value=25)  # fill missing values with 25\n",
    "    else:\n",
    "        raise ValueError('metric must be milliseconds or position')\n",
    "\n",
    "    model_data.reset_index(inplace=True)\n",
    "\n",
    "    driver_feature = pd.read_csv('data/driver_feature_model3_coef.csv')\n",
    "    model_data = model_data.merge(driver_feature[['driverId','coef']], on=['driverId'], how='left')\n",
    "    model_data['coef'] = model_data['coef'].fillna(model_data['coef'].quantile(0.95)) # these are drivers that don't have a coef due to only being in 1 race -- impute with 95th percentile value\n",
    "\n",
    "    # Finishing positions (Y)\n",
    "    positions = races[['raceId','driverId','positionText']].drop_duplicates().reset_index(drop=True)\n",
    "    model_position_text_map = {'Retired':'25','Disqualified':'25', 'not classified':'25','Excluded':'25'}\n",
    "\n",
    "    positions['y'] = positions['positionText'].replace(model_position_text_map)\n",
    "    positions.drop(['positionText'], axis=1, inplace=True)\n",
    "    prev_len = model_data.shape[0]\n",
    "    model_data = model_data.merge(positions, on=['raceId','driverId'], how='left')\n",
    "    #display(model_data['Y'].value_counts())\n",
    "\n",
    "    assert model_data.shape[0] == prev_len, 'duplicates formed during merge'\n",
    "    assert model_data.groupby(['raceId','driverId'])['y'].nunique().max() == 1, 'each driver should have one finishing position'\n",
    "    assert model_data['y'].isin(['Withdrawn','failed to qualify']).sum() == 0, 'should not have any drivers who withdrew or failed to qualify'\n",
    "    model_data['y'] = model_data['y'].astype(int)\n",
    "    assert model_data.groupby(['raceId'])['y'].min().max() == 1, 'races missing a winner'\n",
    "    assert model_data.groupby(['raceId'])['y'].min().min() == 1, 'positions < 1'\n",
    "    assert model_data.groupby(['raceId'])['y'].max().max() <= 25, 'race has position > 24'\n",
    "    assert model_data.isna().sum().sum() ==0\n",
    "\n",
    "    assert model_data.isna().sum().sum() == 0, 'there are null values'\n",
    "    # add rows if number of drivers in a race is less than 24\n",
    "    model_data = model_data.groupby('raceId').apply(pad_race).reset_index(drop=True)\n",
    "    if metric == 'milliseconds':\n",
    "        model_data.fillna(0, inplace=True)\n",
    "    else:\n",
    "        model_data.fillna(25, inplace=True)\n",
    "        assert model_data['y'].min() == 1, 'positions < 1'\n",
    "\n",
    "    \n",
    "\n",
    "     # replace data with randomly ordered copies\n",
    "    model_data = model_data.groupby('raceId', group_keys=False).apply(randomize_race, (race_copies)).reset_index(drop=True)\n",
    "    # Create 'model_driverId' within each 'copy_id' group\n",
    "    model_data['model_driverId'] = model_data.groupby('copy_id').cumcount() + 1\n",
    "\n",
    "    train_df, valid_df, test_df = train_test_split_by_id(model_data, 'copy_id')\n",
    "\n",
    "    train_df_mf = pivot_model_data(train_df).set_index('copy_id')\n",
    "    valid_df_mf = pivot_model_data(valid_df).set_index('copy_id')\n",
    "    test_df_mf = pivot_model_data(test_df).set_index('copy_id')\n",
    "\n",
    "    n_features = n_drivers * len(laps_to_consider)\n",
    "    if coef:\n",
    "        n_features += n_drivers\n",
    "\n",
    "    train_X, train_y = train_df_mf.iloc[:,:n_features], train_df_mf.iloc[:,n_features:]\n",
    "    valid_X, valid_y = valid_df_mf.iloc[:,:n_features], valid_df_mf.iloc[:,n_features:]\n",
    "    test_X, test_y = test_df_mf.iloc[:,:n_features], test_df_mf.iloc[:,n_features:]\n",
    "    \n",
    "    coef_text = 'coef' if coef else 'no_coef'\n",
    "\n",
    "    #binary_str = 'binary' if binary_y else 'categorical'\n",
    "    path = '{}/{}/{}/{}/'.format(path, metric, coef_text, laps_text)\n",
    "\n",
    "    # make folder if doesn't exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # print(train_X.shape, train_y.shape)\n",
    "    # print(valid_X.shape, valid_y.shape)\n",
    "    # print(test_X.shape, test_y.shape)\n",
    "    \n",
    "    train_X.to_csv('{}{}copies_X_train.csv'.format(path, race_copies), index=True)\n",
    "    train_y.to_csv('{}{}copies_y_train.csv'.format(path, race_copies), index=True)\n",
    "    valid_X.to_csv('{}{}copies_X_valid.csv'.format(path, race_copies), index=True)\n",
    "    valid_y.to_csv('{}{}copies_y_valid.csv'.format(path, race_copies), index=True)\n",
    "    test_X.to_csv('{}{}copies_X_test.csv'.format(path, race_copies), index=True)\n",
    "    test_y.to_csv('{}{}copies_y_test.csv'.format(path, race_copies), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max number drivers per race 24\n",
      "max number drivers per race 24\n",
      "max number drivers per race 24\n",
      "max number drivers per race 24\n",
      "max number drivers per race 24\n",
      "max number drivers per race 24\n",
      "max number drivers per race 24\n",
      "max number drivers per race 24\n"
     ]
    }
   ],
   "source": [
    "path = 'Data/RaceMultiOutputModelRandomized2/'\n",
    "\n",
    "# delete everything in path\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(root, file))\n",
    "    for dir in dirs:\n",
    "        shutil.rmtree(os.path.join(root, dir))\n",
    "\n",
    "# Baseline datasets\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[1], laps_text='Lap1',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[2], laps_text='Lap2',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[3], laps_text='Lap3',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[4], laps_text='Lap4',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[5], laps_text='Lap5',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[6], laps_text='Lap6',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[7], laps_text='Lap7',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[8], laps_text='Lap8',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[9], laps_text='Lap9',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[10], laps_text='Lap10',\n",
    "                race_copies=1, metric='position', path=path)\n",
    "\n",
    "\n",
    "\n",
    "# Laps1to10. Laps1to5 datasets\n",
    "for metric in ['position']:\n",
    "    for coef in [True, False]:\n",
    "    \n",
    "\n",
    "        make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[1], laps_text='Lap1',\n",
    "                coef=coef, race_copies=3, metric=metric, path=path)\n",
    "        make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[10], laps_text='Lap10',\n",
    "                coef=coef, race_copies=3, metric=metric, path=path)\n",
    "        make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[1,2,3,4,5], laps_text='Laps1to5',\n",
    "                        coef=coef, race_copies=3, metric=metric, path=path)\n",
    "        make_model_data(laptimes_raw_df=laptimes_raw_df, races=races, laps_to_consider=[1,2,3,4,5,6,7,8,9,10], laps_text='Laps1to10',\n",
    "                        coef=coef, race_copies=3, metric=metric, path=path)\n",
    "    \n",
    "notify('done building datasets','')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
